{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>548.130011</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price     feature1     feature2\n",
       "0  461.527929   999.787558   999.766096\n",
       "1  548.130011   998.861615  1001.042403\n",
       "2  410.297162  1000.070267   998.844015\n",
       "3  540.382220   999.952251  1000.440940\n",
       "4  546.024553  1000.446011  1000.338531"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/fake_reg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x185d72fc688>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df[['feature1','feature2']].values\n",
    "y = df['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74046017, 0.32583248],\n",
       "       [0.43166001, 0.2555088 ],\n",
       "       [0.18468554, 0.70500664],\n",
       "       ...,\n",
       "       [0.54913363, 0.79933822],\n",
       "       [0.2834197 , 0.38818708],\n",
       "       [0.56282703, 0.42371827]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39533339,  0.38540671],\n",
       "       [ 0.57300502,  0.74070924],\n",
       "       [ 0.61294076,  0.65734264],\n",
       "       [ 0.38169528,  0.73076311],\n",
       "       [ 0.07776591,  0.46323644],\n",
       "       [ 0.49421971,  0.68949258],\n",
       "       [ 0.2065742 ,  0.70096247],\n",
       "       [ 0.55141988,  0.41776773],\n",
       "       [ 0.36812191,  0.69082394],\n",
       "       [ 0.56465724,  0.3877465 ],\n",
       "       [ 0.57048029,  0.71810824],\n",
       "       [ 0.79569525,  0.47979901],\n",
       "       [ 0.38488235,  0.41856516],\n",
       "       [ 0.33142545,  0.42411972],\n",
       "       [ 0.89361377,  0.63912775],\n",
       "       [ 0.50191166,  0.39789174],\n",
       "       [ 0.7159808 ,  0.43688384],\n",
       "       [ 0.35812192,  0.92028225],\n",
       "       [ 0.49989367,  0.85589311],\n",
       "       [ 0.63965434,  0.59024789],\n",
       "       [ 0.19053626,  0.34203634],\n",
       "       [ 0.40982896,  0.45849208],\n",
       "       [ 0.26844791,  0.40167269],\n",
       "       [ 0.38649709,  0.33592759],\n",
       "       [ 0.50654703,  0.65789843],\n",
       "       [ 0.41260556,  0.79338075],\n",
       "       [ 0.45631316,  0.61323307],\n",
       "       [ 0.44064792,  0.40889315],\n",
       "       [ 0.42963904,  0.87598452],\n",
       "       [ 0.5145433 ,  0.34457637],\n",
       "       [ 0.53589468,  0.39199459],\n",
       "       [ 0.46139966,  0.51485328],\n",
       "       [ 0.44369075,  0.42880573],\n",
       "       [ 0.49063994,  0.89952766],\n",
       "       [ 0.59785881,  0.32523307],\n",
       "       [ 0.28446406,  0.4651156 ],\n",
       "       [ 0.77957933,  0.39234978],\n",
       "       [ 0.53706097,  0.61018179],\n",
       "       [ 0.25989698,  0.66393142],\n",
       "       [ 0.11552588,  0.50295721],\n",
       "       [ 0.6318509 ,  0.70171257],\n",
       "       [ 0.48801329,  0.36279903],\n",
       "       [ 0.60976949,  0.68389143],\n",
       "       [ 0.63095152,  0.35195791],\n",
       "       [ 0.46866324,  0.54548323],\n",
       "       [ 0.85019104,  0.51945821],\n",
       "       [ 0.83979528,  0.70163971],\n",
       "       [ 0.57599467,  0.46915954],\n",
       "       [ 0.45446128,  0.18040915],\n",
       "       [ 0.43326779,  0.52930506],\n",
       "       [ 0.53232326,  0.54514241],\n",
       "       [ 0.5104231 ,  0.28110178],\n",
       "       [ 0.71924183,  0.50314927],\n",
       "       [ 0.40781023,  0.38597225],\n",
       "       [ 0.66211305,  0.73333352],\n",
       "       [ 0.41355453,  0.55046795],\n",
       "       [ 0.35345356,  0.85769268],\n",
       "       [ 0.8172902 ,  0.62751444],\n",
       "       [ 0.44700765,  0.44473536],\n",
       "       [ 0.32173317,  0.58272804],\n",
       "       [ 0.35972159,  0.57708269],\n",
       "       [ 0.52777368,  0.460713  ],\n",
       "       [ 0.67041025,  0.81296852],\n",
       "       [ 0.2983858 ,  0.42906031],\n",
       "       [ 0.65419814,  0.85816691],\n",
       "       [ 0.46450637,  0.71876496],\n",
       "       [ 0.56986751,  0.66026552],\n",
       "       [ 0.62009871,  0.54371935],\n",
       "       [ 0.44601909,  0.52130557],\n",
       "       [ 0.35080251,  0.63304989],\n",
       "       [ 0.39240226,  0.2974618 ],\n",
       "       [ 0.50365245,  0.60690861],\n",
       "       [ 0.45964199,  0.68916904],\n",
       "       [ 0.77715135,  0.44736318],\n",
       "       [ 0.48462568,  0.43971558],\n",
       "       [ 0.57572343,  0.55193792],\n",
       "       [ 0.64582759,  0.46888802],\n",
       "       [ 0.27203695,  0.52327051],\n",
       "       [ 0.45405772,  0.63661587],\n",
       "       [ 0.77439033,  0.67652698],\n",
       "       [ 0.1788543 ,  0.61512972],\n",
       "       [ 0.59603014,  0.61521319],\n",
       "       [ 0.81871858,  0.75616678],\n",
       "       [ 0.34815992,  0.51704866],\n",
       "       [ 0.48163413,  0.95886913],\n",
       "       [ 0.42444325,  0.50782896],\n",
       "       [ 0.59813691,  0.28152483],\n",
       "       [ 0.51781834,  0.6899035 ],\n",
       "       [ 0.64058053,  0.32854994],\n",
       "       [ 0.5677411 ,  0.47030439],\n",
       "       [ 0.62171107,  0.70355543],\n",
       "       [ 0.55626093,  0.37556544],\n",
       "       [ 0.28293   ,  0.54224094],\n",
       "       [ 0.36850431,  0.45941315],\n",
       "       [ 0.30905233,  0.63402852],\n",
       "       [ 0.48920938,  0.75134084],\n",
       "       [ 0.30612937,  0.25959956],\n",
       "       [ 0.4893308 ,  0.40200188],\n",
       "       [ 0.56898409,  0.56580728],\n",
       "       [ 0.36054139,  0.63246932],\n",
       "       [ 0.37715079,  0.79960251],\n",
       "       [ 0.44019866,  0.60708625],\n",
       "       [ 0.49132264,  0.19382744],\n",
       "       [ 0.73283645,  0.56595157],\n",
       "       [ 0.11913356,  0.57509245],\n",
       "       [ 0.81651358,  0.49716017],\n",
       "       [ 0.51386365,  0.54640496],\n",
       "       [ 0.29422406,  0.40635855],\n",
       "       [ 0.257302  ,  0.77987727],\n",
       "       [ 0.69295744,  0.3393722 ],\n",
       "       [ 0.34320142,  0.49869931],\n",
       "       [ 0.60998783,  0.75785862],\n",
       "       [ 0.64257897,  0.5053132 ],\n",
       "       [ 0.64810558,  0.55596935],\n",
       "       [ 0.39186852,  0.4122828 ],\n",
       "       [ 0.40269177,  0.53079874],\n",
       "       [ 0.54471161,  0.67955115],\n",
       "       [ 0.48562647,  0.87264883],\n",
       "       [ 0.5216583 ,  0.92203428],\n",
       "       [ 0.32327745,  0.93635669],\n",
       "       [ 0.51829851,  0.63989342],\n",
       "       [ 0.60403744,  0.48127254],\n",
       "       [ 0.19808441,  0.45219614],\n",
       "       [ 0.21235677,  0.22402339],\n",
       "       [ 0.52103298,  0.47432954],\n",
       "       [ 0.75275881,  0.63771274],\n",
       "       [ 0.56222912,  0.23841019],\n",
       "       [ 0.49388902,  0.55391671],\n",
       "       [ 0.26512554,  0.66400075],\n",
       "       [ 0.35839536,  0.58251275],\n",
       "       [ 0.46853745,  0.50187999],\n",
       "       [ 0.21779058,  0.51032544],\n",
       "       [ 0.40760834,  0.5582352 ],\n",
       "       [ 0.47412131,  0.4808989 ],\n",
       "       [ 0.7584014 ,  0.60263361],\n",
       "       [ 0.80476446,  0.52531515],\n",
       "       [ 0.15750364,  0.52209449],\n",
       "       [ 0.62297643,  0.73054697],\n",
       "       [ 0.54220998,  0.4370445 ],\n",
       "       [ 0.64071817,  0.58729863],\n",
       "       [ 0.37624254,  0.39561819],\n",
       "       [ 0.47207617,  0.60505174],\n",
       "       [ 0.50689808,  0.6699942 ],\n",
       "       [ 0.25653288,  0.3559246 ],\n",
       "       [ 0.43516389,  0.65904556],\n",
       "       [ 0.54183606,  0.71511953],\n",
       "       [ 0.31588989,  0.38194033],\n",
       "       [ 0.37163359,  0.6752128 ],\n",
       "       [ 0.53636781,  0.6351209 ],\n",
       "       [ 0.57491804,  0.39358871],\n",
       "       [ 0.60006421,  0.74498547],\n",
       "       [ 0.15783876,  0.43528378],\n",
       "       [ 0.31897328,  0.56290091],\n",
       "       [ 0.31548972,  0.67541007],\n",
       "       [ 0.45188635,  0.2906613 ],\n",
       "       [ 0.29686209,  0.54737882],\n",
       "       [ 0.27484316,  0.50765114],\n",
       "       [ 0.44483475,  0.55013572],\n",
       "       [ 0.51633816,  0.20581917],\n",
       "       [ 0.49875004,  0.31423739],\n",
       "       [ 0.632033  ,  0.67321752],\n",
       "       [ 0.54142042,  0.51915289],\n",
       "       [ 0.40612168,  0.50857201],\n",
       "       [ 0.57768636,  0.46826385],\n",
       "       [ 0.708897  ,  0.49480014],\n",
       "       [ 0.28950684,  0.31417882],\n",
       "       [ 0.82355331,  0.39180333],\n",
       "       [ 0.3483919 ,  0.09512343],\n",
       "       [ 0.48240186,  0.54299294],\n",
       "       [ 0.26649733,  0.7243406 ],\n",
       "       [ 0.42134372,  0.54318814],\n",
       "       [ 0.73390461,  0.35227035],\n",
       "       [ 0.41026323,  0.3522237 ],\n",
       "       [ 0.65221434,  0.28123699],\n",
       "       [ 0.44187649,  0.65521993],\n",
       "       [ 0.29028069,  0.58014879],\n",
       "       [ 0.39201149,  0.74137242],\n",
       "       [ 0.28244543,  0.61236049],\n",
       "       [ 0.31181604,  0.82351872],\n",
       "       [ 0.63279554,  0.5560242 ],\n",
       "       [ 0.59571019,  0.56406432],\n",
       "       [ 0.49307937,  0.53062721],\n",
       "       [ 0.52882815,  0.80770326],\n",
       "       [ 0.47291646,  0.66193458],\n",
       "       [ 0.80615232,  0.53347541],\n",
       "       [ 0.64767081,  0.34002497],\n",
       "       [ 0.5694891 ,  0.32045986],\n",
       "       [ 0.23316186,  0.49515027],\n",
       "       [ 0.66732072,  0.58391995],\n",
       "       [ 0.47633907,  0.75883219],\n",
       "       [ 0.54624806,  0.37701219],\n",
       "       [ 0.5280346 ,  0.48784086],\n",
       "       [ 0.36401195,  0.77098537],\n",
       "       [ 0.36172013,  0.6455878 ],\n",
       "       [ 0.29850817,  0.33584867],\n",
       "       [ 0.49565511,  0.82318014],\n",
       "       [ 0.37724049,  0.64332928],\n",
       "       [ 0.34110919,  0.27400214],\n",
       "       [ 0.4446484 ,  0.53845677],\n",
       "       [ 0.57213337,  0.3082775 ],\n",
       "       [ 0.60409208,  0.69106798],\n",
       "       [ 0.52224297,  0.20376625],\n",
       "       [ 0.65646516,  0.49451391],\n",
       "       [ 0.48175209,  0.34167122],\n",
       "       [-0.01410839,  0.28897307],\n",
       "       [ 0.59595942,  0.51917617],\n",
       "       [ 0.62368454,  0.14240428],\n",
       "       [ 0.15953323,  0.41374739],\n",
       "       [ 0.72472577,  0.57046806],\n",
       "       [ 0.58406826,  0.31562953],\n",
       "       [ 0.41624278,  0.67069806],\n",
       "       [ 0.40173754,  0.61717449],\n",
       "       [ 0.09025068,  0.74952807],\n",
       "       [ 0.39129383,  0.22402463],\n",
       "       [ 0.16436558,  0.49678277],\n",
       "       [ 0.40587128,  0.78010152],\n",
       "       [ 0.44487418,  0.79226894],\n",
       "       [ 0.24728692,  0.8599148 ],\n",
       "       [ 0.73246664,  0.54611238],\n",
       "       [ 0.29521621,  0.5729201 ],\n",
       "       [ 0.4639173 ,  0.46340204],\n",
       "       [ 0.44176873,  0.57180607],\n",
       "       [ 0.55467089,  0.38939173],\n",
       "       [ 0.68562916,  0.45763472],\n",
       "       [ 0.22692249,  0.66526314],\n",
       "       [ 0.48257754,  0.33203184],\n",
       "       [ 0.54078185,  0.72005117],\n",
       "       [ 0.23086484,  0.16784199],\n",
       "       [ 0.65123035,  0.71179209],\n",
       "       [ 0.86573192,  0.5268671 ],\n",
       "       [ 0.46973135,  0.19028123],\n",
       "       [ 0.29955478,  0.58320343],\n",
       "       [ 0.60286543,  0.66883838],\n",
       "       [ 0.41677795,  0.32030854],\n",
       "       [ 0.41606994,  0.48651484],\n",
       "       [ 0.4896751 ,  0.17612868],\n",
       "       [ 0.6464676 ,  0.49187803],\n",
       "       [ 0.61542612,  0.28588069],\n",
       "       [ 0.5929732 ,  0.59439439],\n",
       "       [ 0.66321565,  0.73356013],\n",
       "       [ 0.46311596,  0.61889648],\n",
       "       [ 0.57449099,  0.49582616],\n",
       "       [ 0.73591816,  0.68387827],\n",
       "       [ 0.57761502,  0.51876189],\n",
       "       [ 0.49463334,  0.59300732],\n",
       "       [ 0.34415736,  0.64092721],\n",
       "       [ 0.48787375,  0.44566992],\n",
       "       [ 0.63785744,  0.47001721],\n",
       "       [ 0.50956637,  0.44243032],\n",
       "       [ 0.79492857,  0.56691957],\n",
       "       [ 0.37979357,  0.51604759],\n",
       "       [ 0.27945211,  0.48686131],\n",
       "       [ 0.3483822 ,  0.68503624],\n",
       "       [ 0.42392129,  0.55090892],\n",
       "       [ 0.23964628,  1.01865159],\n",
       "       [ 0.34801238,  0.34273123],\n",
       "       [ 0.52591427,  0.61798747],\n",
       "       [ 0.5524785 ,  0.65837898],\n",
       "       [ 0.27627988,  0.50218421],\n",
       "       [ 0.42039396,  0.65250017],\n",
       "       [ 0.74451112,  0.58016671],\n",
       "       [ 0.71263669,  0.58215689],\n",
       "       [ 0.61991639,  0.9152325 ],\n",
       "       [ 0.18031634,  0.54693243],\n",
       "       [ 0.48381172,  0.3282921 ],\n",
       "       [ 0.41394375,  0.19108179],\n",
       "       [ 0.3364849 ,  0.50159694],\n",
       "       [ 0.62397331,  0.23799435],\n",
       "       [ 0.3890586 ,  0.66828674],\n",
       "       [ 0.44031289,  0.60153793],\n",
       "       [ 0.78430587,  0.51694283],\n",
       "       [ 0.4431304 ,  0.44856803],\n",
       "       [ 0.57356327,  0.55964003],\n",
       "       [ 0.42370371,  0.32378282],\n",
       "       [ 0.51313398,  0.52265074],\n",
       "       [ 0.45543037,  0.82611348],\n",
       "       [ 0.6987176 ,  0.42124178],\n",
       "       [ 0.42417444,  0.70209803],\n",
       "       [ 0.34096502,  0.54367395],\n",
       "       [ 0.5819292 ,  0.02584364],\n",
       "       [ 0.36897232,  0.62574984],\n",
       "       [ 0.5143083 ,  0.76527682],\n",
       "       [ 0.34456986,  0.29927801],\n",
       "       [ 0.22179862,  0.56242645],\n",
       "       [ 0.36091838,  0.59304667],\n",
       "       [ 0.4921206 ,  0.61709644],\n",
       "       [ 0.67907034,  0.6647662 ],\n",
       "       [ 0.14766961,  0.4725882 ],\n",
       "       [ 0.19296391,  0.57449626],\n",
       "       [ 0.52465099,  0.47822955],\n",
       "       [ 0.47737293,  0.73662192],\n",
       "       [ 0.25942707,  0.64318087],\n",
       "       [ 0.33331191,  0.24587449],\n",
       "       [ 0.50211082,  0.63687026],\n",
       "       [ 0.44485012,  0.4408569 ],\n",
       "       [ 0.36842211,  0.6496984 ],\n",
       "       [ 0.0178803 ,  0.79438818],\n",
       "       [ 0.59413373,  0.70213846],\n",
       "       [ 0.53929518,  0.33822417],\n",
       "       [ 0.2903287 ,  0.44841353]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples\n",
      "Epoch 1/250\n",
      " 32/700 [>.............................] - ETA: 20s"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(32, 2), b.shape=(2, 4), m=32, n=4, k=2\n\t [[node sequential/dense/MatMul (defined at <ipython-input-10-be0cb4fedb19>:1) ]] [Op:__inference_distributed_function_818]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-be0cb4fedb19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(32, 2), b.shape=(2, 4), m=32, n=4, k=2\n\t [[node sequential/dense/MatMul (defined at <ipython-input-10-be0cb4fedb19>:1) ]] [Op:__inference_distributed_function_818]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
